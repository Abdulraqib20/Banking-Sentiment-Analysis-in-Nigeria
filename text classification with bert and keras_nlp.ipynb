{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225483a0-66ba-4af9-baec-d89e96e8cbea",
   "metadata": {},
   "source": [
    "## Text Classification With BERT and KerasNLP\n",
    "\n",
    "Now since I am done building the sentiment analysis model using the XGBoost algorithm, I will make use of BERT, a popular Masked Language Model which is bidirectional (it has access to the words left and right) to build a the text classification model and also KerasNLP, which provides a simple Keras API for training and finetuning NLP models to classify the sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496e2c5a-081a-4b6d-a5ac-8729b625eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_nlp\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132bbde9-cc0c-4528-acdc-7a584fb40ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_name</th>\n",
       "      <th>time_of_tweet</th>\n",
       "      <th>hour_of_the_day</th>\n",
       "      <th>processed_tweet</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>character_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We celebrate our dynamic GMD/CEO; Dr. Ebenezer...</td>\n",
       "      <td>2023-06-07 07:28:33</td>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>7</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>07:28:33</td>\n",
       "      <td>7</td>\n",
       "      <td>celebrate dynamic gmdceo dr ebenezer onyeagwu ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>91</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you believe it, you will get it.</td>\n",
       "      <td>2023-06-07 06:25:39</td>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>7</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>06:25:39</td>\n",
       "      <td>6</td>\n",
       "      <td>believe get</td>\n",
       "      <td>negative</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you believe it, you will get it.</td>\n",
       "      <td>2023-06-07 06:17:12</td>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>7</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>06:17:12</td>\n",
       "      <td>6</td>\n",
       "      <td>believe get</td>\n",
       "      <td>negative</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you believe it, you will get it.</td>\n",
       "      <td>2023-06-07 05:04:10</td>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>7</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>05:04:10</td>\n",
       "      <td>5</td>\n",
       "      <td>believe get</td>\n",
       "      <td>negative</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you believe it, you will get it.\\n\\nSimply ...</td>\n",
       "      <td>2023-06-07 05:02:33</td>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>7</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>05:02:33</td>\n",
       "      <td>5</td>\n",
       "      <td>believe get simply visit information</td>\n",
       "      <td>negative</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet                 time  \\\n",
       "0  We celebrate our dynamic GMD/CEO; Dr. Ebenezer...  2023-06-07 07:28:33   \n",
       "1                If you believe it, you will get it.  2023-06-07 06:25:39   \n",
       "2                If you believe it, you will get it.  2023-06-07 06:17:12   \n",
       "3                If you believe it, you will get it.  2023-06-07 05:04:10   \n",
       "4  If you believe it, you will get it.\\n\\nSimply ...  2023-06-07 05:02:33   \n",
       "\n",
       "   year month  day   day_name time_of_tweet  hour_of_the_day  \\\n",
       "0  2023  June    7  Wednesday      07:28:33                7   \n",
       "1  2023  June    7  Wednesday      06:25:39                6   \n",
       "2  2023  June    7  Wednesday      06:17:12                6   \n",
       "3  2023  June    7  Wednesday      05:04:10                5   \n",
       "4  2023  June    7  Wednesday      05:02:33                5   \n",
       "\n",
       "                                     processed_tweet sentiments  \\\n",
       "0  celebrate dynamic gmdceo dr ebenezer onyeagwu ...   positive   \n",
       "1                                        believe get   negative   \n",
       "2                                        believe get   negative   \n",
       "3                                        believe get   negative   \n",
       "4               believe get simply visit information   negative   \n",
       "\n",
       "   character_count  word_count  \n",
       "0               91          12  \n",
       "1               11           2  \n",
       "2               11           2  \n",
       "3               11           2  \n",
       "4               36           5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the exported data\n",
    "df1 = pd.read_csv('tweets2.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6a97e7-a49f-4ca9-9d44-92c8fffaddfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5495\n",
       "1    4045\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the target labels\n",
    "df1['sentiments'] = df1['sentiments'].replace({\n",
    "    'negative': 0,\n",
    "    'positive': 1\n",
    "})\n",
    "df1['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139f4f0a-69b1-419a-b261-72bbbc9b42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1['tweet']\n",
    "y = df1['sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3139fc-9d48-49ee-9092-26bcbb872064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing of the texts column using NLTK\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r'\\b[0-9]+\\b\\s*', '', text)\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "X_preprocessed = [preprocess_text(text) for text in X]\n",
    "\n",
    "# Split the preprocessed data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad9f6bdd-3e9d-44ff-baae-b3d01e46a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoded format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2, dtype='float32')\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=2, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18439c2c-ee1c-4e1e-8ebb-4e95545c916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pretrained BERT model that has been finetuned for sentiment analysis\n",
    "\n",
    "model_name = \"bert_tiny_en_uncased_sst2\"\n",
    "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
    "    model_name,\n",
    "    num_classes=2,\n",
    "    load_weights = True,\n",
    "    activation='sigmoid' # for the binary classification task\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2fc41e-2f52-4b5b-9479-00d24ba9b4af",
   "metadata": {},
   "source": [
    "The next step is to compile and train the model. The aim here is to use the pre-trained model and finetune it on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f37b2d69-4fda-4ab8-be7a-23c882d5dc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 806s 3s/step - loss: 0.4129 - accuracy: 0.8161 - val_loss: 0.3683 - val_accuracy: 0.8361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24dd4018c40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    jit_compile=True,\n",
    "     metrics=[\"accuracy\"],\n",
    ")\n",
    "# Access backbone programatically (e.g., to change `trainable`).\n",
    "classifier.backbone.trainable = False\n",
    "# Fit again.\n",
    "classifier.fit(x=X_train, y=y_train, validation_data=(X_test,y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699a2f15-f6b1-4236-8cfe-240700c46784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 52s 651ms/step - loss: 0.3683 - accuracy: 0.8361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3683411180973053, 0.8360586762428284]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on the testing data\n",
    "classifier.evaluate(X_test, y_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30a1e1d6-4c13-45aa-ab0a-d23eb6411aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[[0.30848458 0.69052   ]]\n",
      "positive with a 69.05 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "# checking the model to see performance on new samples\n",
    "sentiment_categories = [\"negative\", \"positive\"]\n",
    "scores = classifier.predict([preprocess_text(\"Nigerian Banks are doing pretty okay but need to do better with their awful customer service!\")])\n",
    "print(scores)\n",
    "print(f\"{sentiment_categories[np.argmax(scores)]} with a { (100 * np.max(scores)).round(2) } percent confidence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de68a91a-a4b1-4018-8d6f-9d0710426c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "@ZenithBank, what's up with your ATMs? üèßü§∑‚Äç‚ôÄÔ∏è Half of them are out of cash, and the rest are always broken. Do you guys even maintain them?: negative with a 96.76 percent confidence.\n",
      "\n",
      "I swear @gtbank has the worst online banking platform! üò†üì± It's slow, clunky, and full of bugs. Time to find a better bank.: positive with a 52.71 percent confidence.\n",
      "\n",
      "How hard is it for @UBA to answer a simple email? üìßü§¶‚Äç‚ôÇÔ∏è Been waiting for days, and still no response. Way to treat your customers!: negative with a 96.69 percent confidence.\n",
      "\n",
      "Dear @FidelityBankPLC, your interest rates are a joke! üí§üí§ Might as well keep my money under the mattress.: negative with a 83.24 percent confidence.\n",
      "\n",
      "Just had the best experience at First Bank üéâ Love their friendly staff and quick service! üíØ: positive with a 95.99 percent confidence.\n",
      "\n",
      "Ugh, seriously @ZenithBank? üôÑ Been waiting in line for ages, and no one seems to care. Time to switch banks, I guess. üòí: negative with a 95.63 percent confidence.\n",
      "\n",
      "Shoutout to @FidelityBankPLC üôå Just got my savings interest, and it's way better than I expected! üí∞: positive with a 94.33 percent confidence.\n",
      "\n",
      "Naija banks, step up your game! üöÄ We need more innovative products and better customer support!: positive with a 92.66 percent confidence.\n",
      "\n",
      "Make una no go vex perosn with this early morning poor service all this banks ooo!: negative with a 96.21 percent confidence.\n",
      "\n",
      "Zenith bank, abeg make una allow this money drop or revise it. Abeg, the money is in need for urgent medical attention: positive with a 51.28 percent confidence.\n",
      "\n",
      "Awon Bank yi ti ya werey sha: negative with a 96.7 percent confidence.\n",
      "\n",
      "Why am I receiving pos debit for February and March over a declined transaction?? Is the bank robbing me @gtbank_help: negative with a 75.06 percent confidence.\n",
      "\n",
      "Okay, First Bank na better bank: positive with a 94.84 percent confidence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking the model to see performance on new samples\n",
    "sentiment_categories = [\"negative\", \"positive\"]\n",
    "new_examples = [\n",
    "    \"@ZenithBank, what's up with your ATMs? üèßü§∑‚Äç‚ôÄÔ∏è Half of them are out of cash, and the rest are always broken. Do you guys even maintain them?\",\n",
    "    \"I swear @gtbank has the worst online banking platform! üò†üì± It's slow, clunky, and full of bugs. Time to find a better bank.\",\n",
    "    \"How hard is it for @UBA to answer a simple email? üìßü§¶‚Äç‚ôÇÔ∏è Been waiting for days, and still no response. Way to treat your customers!\",\n",
    "    \"Dear @FidelityBankPLC, your interest rates are a joke! üí§üí§ Might as well keep my money under the mattress.\",\n",
    "    \"Just had the best experience at First Bank üéâ Love their friendly staff and quick service! üíØ\",\n",
    "    \"Ugh, seriously @ZenithBank? üôÑ Been waiting in line for ages, and no one seems to care. Time to switch banks, I guess. üòí\",\n",
    "    \"Shoutout to @FidelityBankPLC üôå Just got my savings interest, and it's way better than I expected! üí∞\",\n",
    "    \"Naija banks, step up your game! üöÄ We need more innovative products and better customer support!\",\n",
    "    \"Make una no go vex perosn with this early morning poor service all this banks ooo!\",\n",
    "    \"Zenith bank, abeg make una allow this money drop or revise it. Abeg, the money is in need for urgent medical attention\",\n",
    "    \"Awon Bank yi ti ya werey sha\",\n",
    "    \"Why am I receiving pos debit for February and March over a declined transaction?? Is the bank robbing me @gtbank_help\",\n",
    "    \"Okay, First Bank na better bank\"\n",
    "]\n",
    "\n",
    "scores = classifier.predict([preprocess_text(example) for example in new_examples])\n",
    "\n",
    "for i, score in enumerate(scores):\n",
    "    print(f\"{new_examples[i]}: {sentiment_categories[np.argmax(score)]} with a { (100 * np.max(score)).round(2) } percent confidence.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7157e74-e70b-47a3-be2c-1a87dd8fbe46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
